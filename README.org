* Intro

This repository contains a submodule to record which [[https://github.com/fastai/fastai.git][fast.ai]] commit
was used for a given lesson.  When you clone this repository, don't
forget to
#+BEGIN_SRC shell :exports code
  git submodule init
  git submodule update
#+END_SRC

* [[http://course.fast.ai/lessons/lesson1.html][Lesson 1]] of deep learning course

There's also a fast.ai machine learning course (Where?)

After training a model, look at the overall metrics, and at examples
of each of (see also [[file:fastai/fastai/plots.py::class%20ImageModelResults():][ImageModelResults]]):
1. A few correct labels at random
2. A few incorrect labels at random
3. The most correct labels of each class (ie those with highest probability that are correct)
4. The most incorrect labels of each class (ie those with highest probability that are incorrect)
5. The most uncertain labels (ie those with probability closest to 0.5).

** [[https://arxiv.org/abs/1506.01186][Cyclical Learning Rates for Training Neural Networks]]
- Epoch :: all training examples seen once (example from paper: an
           epoch is calculated by dividing the number of training
           images by the batchsize used.  For example, CIFAR-10 has
           50000 training images and the batchsize is 100 so an epoch
           = 50000 / 100 = 500 iterations).

           From [[https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9][towardsdatascience]]: One Epoch is when an ENTIRE
           dataset is passed forward and backward through the neural
           network only ONCE.
- Batch size :: From [[https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9][towardsdatascience]]: number of training examples
                present in a single batch.
- Iterations :: From [[https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9][towardsdatascience]]: number of batches needed to
                complete one epoch.

** fastai machine                                                     :crypt:
-----BEGIN PGP MESSAGE-----

jA0EBwMCDZOjgvc8GG9g0ukBvAyyS3SVq42F+VAyCTWibV8yPhHIziNnxsUmUZOf
SpOkN2hDAN4MrtZbYbqAn1A11NFHeQ4wbepK9s78MAf9IQfjbb/g8+tIsRvhoQkL
sesGtB/vT60Fd6UT9r9OH7ygn6eCFPgnK/96IMMnxDYaecyQMWnPNKboAn43QRn8
kwKkY+XogRC9aIq2k6yiwW9go7gAe8sRsMt+YR23yAOEq1emcd3jzA96HXZPb/1E
l2PQfuLZXkZINHlgRSSb6FikbBslAXAe2pnsbhQFBB9tTlbNrAqQzdUMKcQCDNOz
BsJnabC1+qHwWYBvhYZcgrF2FsfwGmDrAD2pblgaUw6VYGNlvKDQjNzD+gLL6rVc
dMkrUiNBvt/AqUOScpkgP5UwCdsHBloAmehl6EYSnkvii81F44PPFNsvM8srE1MS
OBrTZuxT4xNOmYlQZRX8B1TyFcgz82d6Q4m3F4dDukuP5qCeEW/a6YcGSI+QfyDW
94oIDo/x6y1m5X2NLFhHVzjrL5JOHTHEcxNPKo7QuYFzHh/OAY7btQhDOpAsjhdr
7VGFHmMSdAF0c9HUhqhh35LlYB9mXtLALy91HOtt1gzlLIRF39YVZO4sO1HXXNlq
1DL+Ut688TqA54J9S5mdNykshUMf4I87aFDQUis1zXyc2aTNt+79SThpoyW0AMhS
BzGa4BYjvRy80rsiBUeu2EUwjVNw9a6SgDCkYMAVWueHJm9F/lPt9hVHbmLYtrwZ
/Wjz
=9StH
-----END PGP MESSAGE-----

** Exercise 1
Made a dataset with flowers (not sure about copyrights so I won't
upload it to GitHub).

See also [[file+emacs:lesson1-exercise.ipynb][lesson1-exercise]] (Jupyter Notebook)

* Exercise for lesson2: dog breed identification
- [[http://forums.fast.ai/t/wiki-lesson-2/9399][Wiki link]]
- [[http://files.fast.ai/models/weights.tgz][Pretrained models]] (e.g. resnext_101_64x4d)

** Kaggle                                                             :crypt:
-----BEGIN PGP MESSAGE-----

jA0EBwMCnaW+0UWTH/5g0msBPOzALsYYxVoZRsdpGr8ocYs2eBZsf1SZ1EbyV29u
klg7R6f9bMwxMj4ykIWy8I+fgwkrxOL3Kzjb8EJFWwUrn5wI1BnmBdxDYKPGHvxe
Z8NigzQiCZMBaQaUHwbQ/uYeJe+LIBLpQnknuQ==
=MfH7
-----END PGP MESSAGE-----

** [[https://www.kaggle.com/c/dog-breed-identification][Dog breed identification]]
#+BEGIN_SRC shell :exports code
  kaggle competitions download -c dog-breed-identification
  cd $HOME/data
  mkdir dogbreed
  unzip -d dogbreed $HOME/.kaggle/competitions/dog-breed-identification/test.zip
  unzip -d dogbreed $HOME/.kaggle/competitions/dog-breed-identification/train.zip
  unzip -d dogbreed $HOME/.kaggle/competitions/dog-breed-identification/labels.csv.zip
#+END_SRC
Puts zip files in
~$HOME/.kaggle/competitions/dog-breed-identification~ and unzip in our
data folder.

** Summary recommended by instructor
https://medium.com/@apiltamang/case-study-a-world-class-image-classifier-for-dogs-and-cats-err-anything-9cf39ee4690e

* [[http://course.fast.ai/lessons/lesson3.html][Lesson 3]]
** softmax vs sigmoid
*** Softmax
Use for single label classification: goal is to have activation
function interpretable as probability (0 <= p <= 1, sum to 1).

Take all outputs, exponentiate them.  Then each exponentiated output
is normalized by the sum.
*** sigmoid
Use for multi-label classification: goal is to have activation
functions between 0 and 1.

sigmoid(x) = e(x) / (1 + e(x))

** AWS setup
See [[https://www.youtube.com/watch?v=9C06ZPF8Uuc&feature=player_embedded][start of video]] or [[https://github.com/reshamas/fastai_deeplearn_part1/blob/master/tools/aws_ami_gpu_setup.md][reshamas:aws_ami_gpu_setup.md]].

** Panda library
Recommended book: [[http://wesmckinney.com/pages/book.html][Python for Data Analysis Book]] ([[http://amzn.to/2vvBijB][Amazon]]) 2nd edition.

* Lesson 4

** Cool techniques to improve models
*** [[https://arxiv.org/abs/1704.00109][Snapshot Ensembles: Train 1, get M for free]]
Cited in [[https://techburst.io/improving-the-way-we-work-with-learning-rate-5e99554f163b][Improving the way we work with learning rate]].
*** [[https://towardsdatascience.com/stochastic-weight-averaging-a-new-way-to-get-state-of-the-art-results-in-deep-learning-c639ccf36a][Stochastic Weight Averaging]]
Instead of taking snapshots and ensembling them (previous link), keep
a running average of them.

* [[http://forums.fast.ai/t/wiki-lesson-4/9402][Lesson 4]]
- [[https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-4-2048a26d58aa][Deep Learning 2: Part 1 Lesson 4 â€“ Transcript by Hiromi Suenaga]]
** Part 1: Structured data (predicting sales) up to 1h20m
*** Data
See [[https://www.youtube.com/watch?v=9C06ZPF8Uuc&feature=youtu.be][lesson 3 (around 2h06)]]:
#+BEGIN_SRC shell :exports code
  wget http://files.fast.ai/part2/lesson14/rossman.tgz
#+END_SRC
*** Dropout (around 0h10)
Reduce risk of overfitting: each minibatch throws out different
activations with a given probability.

Dropout is disabled (only?) in fast.ai while computing loss for
validation set: this is why in the early stages of training,
validation loss can be lower than training loss.

Dropout needs to rescale activations to preserve meaning: assuming
dropout probability=0.5, the output would only be half of what is was
before, leading subsequent layers to believe that a feature is present
for a lower threshold.  This leads to problems when using the model in
prediction (i.e. without dropout).
*** [[http://www.fast.ai/2017/11/13/validation-sets/][Choosing a validation set]]
For time dependent data, normally the application wants to predict
recent data from past observations, so the validation set is best
chosen as the most recent training data available.

** Part 2: 1h20m36s

* Common code snippets
** Initialization
#+BEGIN_EXAMPLE
  %reload_ext autoreload
  %autoreload 2
  %matplotlib inline
  from fastai.imports import *
  from fastai.torch_imports import *
  from fastai.transforms import *
  from fastai.conv_learner import *
  from fastai.model import *
  from fastai.dataset import *
  from fastai.sgdr import *
  from fastai.plots import *
#+END_EXAMPLE
